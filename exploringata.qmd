---
title: "Analyzing the impacts of temperature on rockfish recruitment in the Channel Islands"
date: 12/4/2025
format: html
execute:
  warning: false
  message: false
---

![Photo from SeaDoc Society](images/yoy.jpeg){fig-align="center"}

## Background

Rockfish (genus *Sebastes*) are an important commercial and recreational fishing target on the west coast. The early life stages of Rockfish are spent in the water column until they grow strong enough to swim to structure. With global ocean temperatures increasing, I aim to analyze how increases in water temperature during Pelagic Larval Duration (PLD) affects the abundance of new rockfish, or Young of Year (YOY). I will utilize timeseries data of YOY abundance collected at the Northern Channel Islands. During data collection, California experienced a marine heatwave often referred to as "The Blob" during 2014-2016. I will analyze the effects of temperature on YOY abundance from 2012 to 2019 in order to determine if the warmer waters during the Blob influenced abundance and give insight to how the population may change has global ocean temperatures increase due to climate change. Additionally, I will incorporate the impacts of upwelling, which supplies nutrients to YOY during the PLD.

## About the data

The data quantifying Rockfish recruitment comes from the Partnership of Interdiscpilnary Sciences of Coastal Oceans (PISCO) long-term fish recruitment monitoring in the Channel Islands. The YOYs were collected using Standardized Monitoring Units for the Recruitment of Fishes (SMURFs) that were placed just off the coast of the Northern Channel Islands in an attempt to collect recruit fish as they swam to structure. Monitoring took place from 2000-2018, with collections occuring year round starting in 2012.

NOAA data is used to quantify temperature with Sea Surface Temperature (SST) lag 30 days from time of collection to predict SST during PLD. Upwelling was quanitified using the Biological Effective Upwelling Transport Index (BEUTI) lag 30 days. 

## Hypotheses

H0: Temperature has no effect on rockfish recruitment

Ha: Increased temperature has a positive effect on rockfish recruitment

## Directed Acyclic Grad (DAG)

![](images/dag.png)
Upwelling is the result of moving water, often bringing cold, nutrient rich water from the deep up to the surface. This impacts the SST, decreasing temperature during mass upwelling. Additionally, the nutrients supplied in upwelling have a direct impact on YOY development, providing necessary nutrients during the PLD. The temprature also impacts fish development in the PLD, with faster development occuring at warmer temperatures.



## Load necessary packages and data
```{r}
library(tidyverse)
library(knitr)
library(pscl)
library(modelsummary)
library(MASS)
library(ggeffects)

smurf <- read_csv("data/PISCO_UCSB_subtidal_recruitment_fish_data.1.2.csv")

smurf_sp <- read_csv("data/PISCO_UCSB_subtidal_recruitment_fish_spp_list.1.2.csv")



# Data for ocean temperature and upwelling
ocean <- read_csv("data/ALL_OCEAN_DATA.csv")


```

## Data Cleaning

Before I can start working on my statistical modelings, I need to do some cleaning and filtering to get the data ready to be analyzed. I first subset my data to include only my species of interest. I chose Copper, Kelp, Gopher, Grass, and Brown rockfish, because they have similar PLDs and are difficult to differentiate at a small size. I chose to look at data between 2012-2019 to include before, during, and after the Blob. I also narrowed the window of sampling by year to only include sampling during the months of recruitment to avoid a seasonal pattern from emerging. I chose to only look at the two most consistently sampled sites, which were located at Santa Cruz island.

```{r}
recruits <- left_join(smurf, smurf_sp)


recruits$Date <- as.Date(paste(recruits$year, recruits$month, recruits$day, sep = "/"))
ocean$Date <- as.Date(ocean$Date, format = "%m/%d/%Y")

recruit_ocean <- left_join(recruits, ocean)
  

rf_yoy <- recruit_ocean %>% 
  filter(year >= 2012  &
        (month >= 2 & month <= 7)) %>% 
  filter(str_detect(site_code, "HAZ")| # Filter data for on Pelican and Hazards sample sites
            str_detect(site_code, "PEL")) %>% 
  filter(classcode == "KGBC" | classcode == "SCAR/SCAU" | classcode == "SATR") %>% 
  dplyr::select(year, month, day, classcode, total_fish_collected, SST_D30, beuti_30)
      
  


summarized_yoy <- rf_yoy %>% 
  group_by(classcode, year) %>% 
  summarise(count = sum(total_fish_collected))


highest_rf <- recruits %>% 
  filter(genus == "Sebastes") %>% 
  group_by(classcode) %>% 
  summarise(count = sum(total_fish_collected)) %>% 
  filter(count >= 1000)

most_yoy <- highest_rf$classcode


```

```{r}
rf_yoy_av <- rf_yoy %>% 
  group_by(classcode, month) %>% 
  summarise(av_fish = mean(total_fish_collected)) %>% 
  ungroup()
```

```{r}
ggplot(rf_yoy_av, aes(month, av_fish)) +
  geom_line(aes(color = classcode)) +
  scale_color_manual(values = c("darkgreen", "brown4", "lightblue")) +
  labs(x = "Year",
       y = "Annual total fish collected",
       title = "Recruit Rockfish counts over time") +
  theme_light()
```

```{r}
for(i in 1:nrow(rf_yoy)){
  if (rf_yoy$total_fish_collected[i] > 0){
    rf_yoy$success[i] <- 1
    }
  else{
    rf_yoy$success[i] <- 0
    }
}
```

## Statistical analysis with a Hurdle Model
In order to analyze this data, I selected a hurdle model because the data contains many 0's. Hurdle models are a type of hierarchical model that first tests presence and absence (0 and 1) with a predictor variable, then tests abundance. For these steps 
$$FishPresence \sim Binomial(1, p) \\ 
logit(p) = \beta_0 + \beta_1 SST + \beta_2 BEUTI$$

$$Fishcount \sim NegativeBinomial(\mu, \theta) \\ 
log(\mu) = \beta_3 + \beta_4 SST + \beta_5 BEUTI$$

For simplicity in understanding the model, I only selected temperature as predictor variable to simulate data and get my beta values returned to me. To begin simulating data, I need to generate x values based on the SST lag 30 days variable from the original data. From there I can use those temperatures and beta values I selected to run the binomial equation to find `logit(p)`. I think take the inverse logit of those values to generate p which represents the probability of success. Using that probability, I simulated a success variable with `rbinom()` to generate 0's and 1's. 

Similar to the binomial step, I chose new beta values for the equation and used the same generated temperature data. The output of the negative binomial equation gives log of mu, or the mean. By applying an exponential to that, the mean of the data is found, which is then used to simulate count data using `rnbinom()`.

```{r}
B0 <- 3
B1 <- -0.1
B2 <- 2
B3 <- 0.1

pres_abs <- expand_grid(mean_sst = seq(0,40, length.out = 1000)) %>% 
  mutate(logit_p = B0 + B1 * mean_sst,
         p = exp(logit_p) / (1 + exp(logit_p)),
         success = rbinom(n = 1000, size = 1, prob = p), 
         log_mu = B2 + B3 * mean_sst,
         mu = exp(log_mu),
         count = rnbinom(n = 1000, size = 1.5, mu = mu))

rf_presence_model <- glm(success ~ mean_sst,  # formula: response ~ resp
                   data = pres_abs, # data remains unchanged
                   family = binomial(link = "logit")
                   )
modelsummary(rf_presence_model)

no_zero <- pres_abs %>% 
  filter(count > 0)

rf_abundance_model <- glm.nb(count ~ mean_sst,  # formula: response ~ resp
                   data = no_zero)
                  
modelsummary(rf_abundance_model)
```
I successfully simulated data, applied the hurdle model, and got my beta values back!


## Generating the predictions with the data
Now I can use my actual data with both predictor variables to predict data based on a hurdle model. Just like before, I will start with a generalized linear model to predict presence and absence. I can then use those predictions to generate confidence intervals
```{r}

pred_grid <- expand_grid(SST_D30 = seq(min(rf_yoy$SST_D30, na.rm = TRUE),
                                           max(rf_yoy$SST_D30, na.rm = TRUE),
                                           length.out = 100),
                         beuti_30 = seq(min(rf_yoy$beuti_30, na.rm = TRUE),
                                           max(rf_yoy$beuti_30, na.rm = TRUE),
                                           length.out = 100))

true_pres_abs_model <- glm(success ~ SST_D30 * beuti_30,
                     data = rf_yoy, # data remains unchanged
                     family = binomial(link = "logit")
                   )


true_pres_abs_pred <- pred_grid %>%  
  mutate(predict = predict(object = true_pres_abs_model,
                          newdata = pred_grid,
                          type = "response"))


rf_presence_model_se <- predict(true_pres_abs_model, newdata = true_pres_abs_pred, type = "link", se.fit = TRUE)


linkinv <- family(true_pres_abs_model)$linkinv

pres_abs_pred <- true_pres_abs_pred %>% 
  mutate(
    logit_p = rf_presence_model_se$fit,
    # 95% CI in link space
    logit_p_se = rf_presence_model_se$se.fit,
    logit_p_lwr = qnorm(0.025, mean = logit_p, sd = logit_p_se),
    logit_p_upr = qnorm(0.975, mean = logit_p, sd = logit_p_se),
    # undo the link function using linkinv
    p = linkinv(logit_p),
    p_lwr = linkinv(logit_p_lwr),
    p_upr = linkinv(logit_p_upr)
  )

ggplot(pres_abs_pred, aes(SST_D30, p)) +
  geom_line() +
  geom_ribbon(aes(ymin = p_lwr, ymax = p_upr), alpha = 0.2) +
  labs(c = "SST") +
  theme_light()
```
## Abundance model
Now that I have predicted values for presence and absence, I need to predit the abundance using a Negative Binomial model. I have to fit the assumption that there are no 0's, so I will filter out the 0's, and predict abudance values.
```{r}
no_zero_yoy <- rf_yoy %>% 
  filter(success == 1)

rf_abundance_model <- glm.nb(total_fish_collected ~ SST_D30 * beuti_30,  # formula: response ~ resp
                   data = no_zero_yoy)


true_abu_pred <- pres_abs_pred %>%
  mutate(predict = predict(object = rf_abundance_model,
                          newdata = pred_grid,
                          type = "response"))

rf_abundance_model_se <- predict(rf_abundance_model, 
                          newdata = true_abu_pred,
                          type = "link", # stay in link space
                          se.fit = TRUE)

linkinv <- family(rf_abundance_model)$linkinv

hurdle_pred <- true_abu_pred %>% 
  mutate(
    log_mu = rf_abundance_model_se$fit,
    # 95% CI in link space
    log_mu_se = rf_abundance_model_se$se.fit,
    log_mu_lwr = qnorm(0.025, mean = log_mu, sd = log_mu_se),
    log_mu_upr = qnorm(0.975, mean = log_mu, sd = log_mu_se),
    # undo the link function using linkinv
    mu = exp(log_mu),
    mu_lwr = exp(log_mu_lwr),
    mu_upr = exp(log_mu_upr)
  )

ggplot(hurdle_pred, aes(SST_D30, log_mu)) +
  geom_ribbon(aes(ymin = log_mu_lwr, ymax = log_mu_upr), alpha = 0.2) +
  geom_line() +
  labs(c = "SST") +
  theme_light()


```
## Hurdle Model prediction
The final step of executing the hurdle model is multiplying my coefficients from the previous equations to get a best fit line. The confidence interval can also be found this way, after transforming into response space.
```{r}
final_hurdle <- hurdle_pred %>% 
  mutate(
    fit = log_mu * logit_p,
    upper_ci = log_mu_upr * logit_p_upr,
    lower_ci = log_mu_lwr * logit_p_lwr)
    
ggplot(final_hurdle, aes(SST_D30, fit)) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.2) +
  geom_line() +
  labs(c = "SST") +
  theme_light()
```
```{r}
final_hurdle
```


## Hurdle model Application
After completing a simulation of data and running a hurdle model, I can apply it to my data. I will add my upwelling variable back in to test my hypothesis
```{r}
true_hurdle_model <- hurdle(total_fish_collected ~ SST_D30 * beuti_30, 
                            data = rf_yoy,
                            dist = "negbin",
                            zero.dist = "binomial")

modelsummary(true_hurdle_model)
```

```{r}
B0 <- 3
B1 <- -0.1
B2 <- 2
B3 <- 0.1

new_recruits <- expand_grid(mean_sst = seq(min(rf_yoy$SST_D30, na.rm = TRUE),
                                           max(rf_yoy$SST_D30, na.rm = TRUE),
                                           length.out = 1000)) %>% 
  mutate(logit_p = B0 + B1 * mean_sst,
         p = exp(logit_p) / (1 + exp(logit_p)),
         success = rbinom(n = 1000, size = 1, prob = p),
         log_mu = B2 + B3 * mean_sst,
         mu = exp(log_mu),
         count = rnbinom(n = 1000, size = 1.5, mu = mu),
         actual_abu = success * count)

sim_hurdle_model <- hurdle(actual_abu ~ mean_sst,  # formula: response ~ resp
                   data = new_recruits, # data remains unchanged
                   zero.dist = "binomial",
                   dist = "negbin"
                   )

modelsummary(sim_hurdle_model)
```

# My Mess
```{r}
pred_grid <- expand_grid(SST_D30 = seq(min(rf_yoy$SST_D30, na.rm = TRUE),
                                           max(rf_yoy$SST_D30, na.rm = TRUE),
                                           length.out = 1000),
                         beuti_30 = seq(min(rf_yoy$beuti_30, na.rm = TRUE),
                                           max(rf_yoy$beuti_30, na.rm = TRUE),
                                           length.out = 1000)) 
  
hurdle_model_pred <- pred_grid %>%  
  mutate(predict = predict(object = true_hurdle_model,
                          newdata = pred_grid,
                          type = "response")) 
```

```{r}
ggplot(data = hurdle_model_pred, aes(x = SST_D30, y = predict)) +
  geom_line(aes(color = beuti_30), alpha = 0.5)+
  scale_color_viridis_c() +
  labs(color = "BEUTI lag 30 days",
       x = "SST degrees C",
       y = "Predicted YOY counts") +
  theme_light()
```



I can use my model to predict confidence intervals
```{r}
ci_hurdle <- confint(true_hurdle_model, level = 0.95)

lower_zero <- ci_hurdle["zero_SST_D30",1]
upper_zero <- ci_hurdle["zero_SST_D30",2]

lower_abu <- ci_hurdle["count_SST_D30",1]
upper_abu <- ci_hurdle["count_SST_D30",2]

ci_hurdle
```




```{r}





new_recruit_pred <- rf_yoy %>% 
  mutate(
    
    zero_upper_ci = upper_zero,
    zero_lower_ci = lower_zero,
    abu_upper_ci = upper_abu,
    abu_lower_ci = lower_abu,
    actual_abu_lower_ci = lower_abu * lower_zero,
    actual_abu_upper_ci = upper_abu * upper_zero
  )
ggplot(new_recruit_pred, aes(mean_sst, total_fish_collected)) +
  geom_line() +
  geom_ribbon(aes(ymin = actual_abu_lower_ci, ymax = actual_abu_upper_ci), alpha = 0.2) +
  geom_point() +
  labs(c = "SST") +
  theme_light()
```




```{r}
new_recruits %>% 
  mutate(
    logit_p = rf_presence_model$fit,
    # 95% CI in link space
    logit_p_se = rf_presence_model_se$se.fit,
    logit_p_lwr = qnorm(0.025, mean = logit_p, sd = logit_p_se),
    logit_p_upr = qnorm(0.975, mean = logit_p, sd = logit_p_se),
    # undo the link function using linkinv
    p = linkinv(logit_p),
    p_lwr = linkinv(logit_p_lwr),
    p_upr = linkinv(logit_p_upr)
  ) %>% 
  ggplot(aes(mean_sst, p)) +
  geom_ribbon(aes(ymin = p_lwr, ymax = p_upr), alpha = 0.2) +
  geom_line() +
  labs(c = "SST") +
  theme_light()
```

```{r}
rf_presence_model_se <- predict(rf_presence_model, 
                          newdata = new_recruits,
                          type = "link", # stay in link space
                          se.fit = TRUE)

linkinv <- family(rf_presence_model)$linkinv


new_recruits %>% 
  mutate(
    logit_p = rf_presence_model$fit,
    # 95% CI in link space
    logit_p_se = rf_presence_model_se$se.fit,
    logit_p_lwr = qnorm(0.025, mean = logit_p, sd = logit_p_se),
    logit_p_upr = qnorm(0.975, mean = logit_p, sd = logit_p_se),
    # undo the link function using linkinv
    p = linkinv(logit_p),
    p_lwr = linkinv(logit_p_lwr),
    p_upr = linkinv(logit_p_upr)
  ) %>% 
  ggplot(aes(mean_sst, p)) +
  geom_ribbon(aes(ymin = p_lwr, ymax = p_upr), alpha = 0.2) +
  geom_line() +
  labs(c = "SST") +
  theme_light()
```


```{r}
pred_grid <- expand_grid(SST_D30 = seq(min(rf_yoy$SST_D30, na.rm = TRUE),
                                           max(rf_yoy$SST_D30, na.rm = TRUE),
                                           length.out = 1000),
                         beuti_30 = mean(rf_yoy$beuti_30))

# reiterate through the boot 1000 times
boot <-  map_dfr(1:1000, \(i) {
  # sample with replacement
  boot_sample <- slice_sample(rf_yoy, n=432, replace = TRUE)
  # run a beta regression on every single boot sample
  boot_mod <- hurdle(total_fish_collected ~ SST_D30 * beuti_30, 
                            data = rf_yoy,
                            dist = "negbin",
                            zero.dist = "binomial")
    # predict the boots values (the outcomes are best fit lines)
  mutate(pred_grid,
         count = predict(object = boot_mod,
                          newdata = pred_grid,
                          type = "response"),
         boot = i)
})


boot %>% 
  summarise(count_lwr = quantile(count, 0.025),
            count_upr = quantile(count, 0.975)) %>% 
  kableExtra::kable()
```

```{r}
count_lwr = quantile(boot$count, 0.025)
count_upr = quantile(boot$count, 0.975)

ggplot(boot, aes(count)) +
  geom_histogram() +
  geom_vline(xintercept = count_lwr, 
             color = "firebrick",
             linetype = "dotted",
             linewidth = 1.5) +
   geom_vline(xintercept = count_upr, 
             color = "firebrick",
             linetype = "dotted",
             linewidth = 1.5) +
  theme_light()
```

```{r}

```




```{r}
ggplot(rf_yoy, aes(month, total_fish_collected)) +
  geom_jitter(aes(color = classcode))
```


```{r}
ggplot(kb_yoy, aes(month, total_fish_collected)) +
  geom_jitter()

```
```{r}
for(i in seq_along(rf_yoy)){
  if (rf_yoy$total_fish_collected[i] >= 1)
    {rf_yoy$success[i] <- 1}
    else
      {rf_yoy$success[i] <- 0}
}
```


## Statistical analysis

FishPresence ~ binomial(1, p)
$$
logit(p) = B0 + B1 * SST
$$
```{r}
B0 <- 3
B1 <- -0.1


logit_p <- B0 + B1 * x

p <- exp(logit_p) / 
  (1 + exp(logit_p))

# Simulate presences and absence
success <- rbinom(n = 1000, size = 1, prob = p)
```

Fishcount ~ NegativeBinomial(r, p)
$$
log(p) = B2 + B3 * SST
$$
```{r}
B2 <- 2
B3 <- 0.1

log_mu <- B2 + B3 * x
mu <- exp(log_mu)

# Simulate count data
count <- rnbinom(n = 1000, size = 1.5, mu = mu)
```


```{r}
rf_presence_model <- glm(success ~ SST_D30 + beuti_30,  # formula: response ~ resp
                   data = rf_yoy, # data remains unchanged
                   family = binomial(link = "logit"))

summary(rf_presence_model)
```

```{r}
x <- seq(min(rf_yoy$SST_D30),max(rf_yoy$SST_D30), length.out = 1)


B0 <- 3
B1 <- -0.1


logit_p <- B0 + B1 * x

p <- exp(logit_p) / 
  (1 + exp(logit_p))

# Simulate presences and absence
success <- rbinom(n = 1000, size = 1, prob = p)

B2 <- 2
B3 <- 0.1

log_mu <- B2 + B3 * x
mu <- exp(log_mu)

# Simulate count data
count <- rnbinom(n = 1000, size = 1.5, mu = mu)


# Create actual count (factor in successes and failures)
actual_count <- success * count


simulated_data <- as_tibble(expand_grid(x, actual_count))

simulated_success <- as_tibble(expand_grid(x, success))

ggplot(simulated_data, aes(x, actual_count)) +
  geom_point()
```

```{r}
glm(success ~ x,
    data = simulated_success,
    family = binomial(link = "logit"))
```


Using 
```{r}
mod.hurdle <- hurdle(total_fish_collected ~ SST_D30, 
                     data = rf_yoy, 
                     dist = "negbin", 
                     zero.dist = "binomial",
                     link = "logit")

summary(mod.hurdle)
```

## generating 0 and 1s
```{r}

```

BEUTI

SST
